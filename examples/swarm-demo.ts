/**
 * AgentDB Swarm Demonstration for AURELIA
 *
 * Comprehensive demo showcasing:
 * - Parallel market data processing
 * - Multi-agent trading strategy execution
 * - Performance comparison: single-agent vs swarm
 * - Real-time metrics and bottleneck detection
 */

import {
  AgentDBSwarmOrchestrator,
  createSwarm,
  SwarmTopology
} from '../src/swarm/agentdb-swarm-orchestrator';
import { AgentType } from '../src/swarm/swarm-agents';
import { TaskPriority } from '../src/swarm/work-stealing-scheduler';

/**
 * Demo 1: Basic Swarm Operations
 */
async function demoBasicSwarm() {
  console.log('\nðŸš€ Demo 1: Basic Swarm Operations\n');

  // Create swarm with adaptive topology
  const swarm = createSwarm({
    topology: SwarmTopology.ADAPTIVE,
    maxAgents: 20,
    minAgents: 4,
    agentdbConfig: {
      dimensions: 1536,
      metric: 'cosine',
      quantization: 'uint8',
      enableHNSW: true,
      enableQUIC: true
    },
    scaling: {
      autoScale: true,
      scaleUpThreshold: 80,
      scaleDownThreshold: 30,
      cooldownPeriod: 5000
    }
  });

  // Start swarm
  await swarm.start();

  // Spawn diverse agent types
  console.log('ðŸ“¦ Spawning specialized agents...');
  await Promise.all([
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.ENCODING),
    swarm.spawnAgent(AgentType.NASH_DETECTION),
    swarm.spawnAgent(AgentType.TRADING)
  ]);

  // Submit simple task
  console.log('ðŸ“‹ Submitting tasks...');
  const taskId = await swarm.submitTask({
    type: 'data_ingestion',
    priority: TaskPriority.HIGH,
    payload: {
      source: 'yahoo',
      symbols: ['SPY', 'QQQ']
    },
    requiredCapabilities: ['data_ingestion']
  });

  // Wait for result
  const result = await swarm.getTaskResult(taskId);
  console.log('âœ… Task completed:', result);

  // Get metrics
  const metrics = swarm.getPerformanceMetrics();
  console.log('\nðŸ“Š Swarm Metrics:');
  console.log(`   Throughput: ${metrics.throughput.toFixed(2)} tasks/sec`);
  console.log(`   Avg Latency: ${metrics.avgLatency.toFixed(2)}ms`);
  console.log(`   Utilization: ${(metrics.avgUtilization * 100).toFixed(1)}%`);
  console.log(`   Success Rate: ${(metrics.successRate * 100).toFixed(1)}%`);

  // Stop swarm
  await swarm.stop();
}

/**
 * Demo 2: Parallel Market Data Processing
 */
async function demoParallelMarketData() {
  console.log('\n\nðŸš€ Demo 2: Parallel Market Data Processing\n');

  const swarm = createSwarm({
    topology: SwarmTopology.MESH,
    maxAgents: 30,
    agentdbConfig: {
      enableHNSW: true,
      quantization: 'uint8',
      enableQUIC: true
    }
  });

  await swarm.start();

  // Spawn multiple data ingestion agents for parallel fetching
  console.log('ðŸ“¦ Spawning data ingestion agents...');
  await Promise.all([
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.DATA_INGESTION)
  ]);

  // Fetch data for multiple symbols in parallel
  const symbols = [
    'SPY', 'QQQ', 'IWM', 'DIA',
    'GLD', 'SLV', 'USO', 'TLT',
    'AAPL', 'MSFT', 'GOOGL', 'AMZN',
    'NVDA', 'TSLA', 'META', 'NFLX'
  ];

  console.log(`ðŸ“‹ Fetching data for ${symbols.length} symbols...`);
  const startTime = Date.now();

  // Submit parallel data ingestion tasks
  const tasks = symbols.map(symbol => ({
    type: 'data_ingestion',
    priority: TaskPriority.HIGH,
    payload: {
      source: 'yahoo',
      symbols: [symbol]
    },
    requiredCapabilities: ['data_ingestion']
  }));

  const taskIds = await swarm.submitBatch(tasks);

  // Wait for all results
  const results = await Promise.all(
    taskIds.map(id => swarm.getTaskResult(id, 10000))
  );

  const elapsed = Date.now() - startTime;

  console.log(`âœ… Fetched ${results.length} symbols in ${elapsed}ms`);
  console.log(`   Throughput: ${(symbols.length / (elapsed / 1000)).toFixed(2)} symbols/sec`);

  const metrics = swarm.getPerformanceMetrics();
  console.log('\nðŸ“Š Performance Metrics:');
  console.log(`   Total Tasks: ${metrics.totalTasks}`);
  console.log(`   Completed: ${metrics.completedTasks}`);
  console.log(`   Avg Latency: ${metrics.avgLatency.toFixed(2)}ms`);
  console.log(`   Agent Utilization: ${(metrics.avgUtilization * 100).toFixed(1)}%`);

  await swarm.stop();
}

/**
 * Demo 3: Multi-Agent Ï†-Mechanics Pipeline
 */
async function demoPhiMechanicsPipeline() {
  console.log('\n\nðŸš€ Demo 3: Ï†-Mechanics Trading Pipeline\n');

  const swarm = createSwarm({
    topology: SwarmTopology.ADAPTIVE,
    maxAgents: 50,
    agentdbConfig: {
      enableHNSW: true,
      quantization: 'uint8',
      enableQUIC: true
    },
    scaling: {
      autoScale: true,
      scaleUpThreshold: 75,
      scaleDownThreshold: 35
    }
  });

  await swarm.start();

  // Spawn complete agent ecosystem
  console.log('ðŸ“¦ Spawning AURELIA agent ecosystem...');
  await Promise.all([
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.ENCODING),
    swarm.spawnAgent(AgentType.ENCODING),
    swarm.spawnAgent(AgentType.NASH_DETECTION),
    swarm.spawnAgent(AgentType.KNOWLEDGE_GRAPH),
    swarm.spawnAgent(AgentType.VISION),
    swarm.spawnAgent(AgentType.TRADING),
    swarm.spawnAgent(AgentType.CONSCIOUSNESS)
  ]);

  console.log('\nðŸ”„ Running Ï†-Mechanics Pipeline...\n');

  // Stage 1: Data Ingestion
  console.log('Stage 1: Data Ingestion');
  const dataTaskId = await swarm.submitTask({
    type: 'data_ingestion',
    priority: TaskPriority.HIGH,
    payload: {
      source: 'yahoo',
      symbols: ['SPY', 'QQQ', 'IWM']
    }
  });

  const marketData = await swarm.getTaskResult(dataTaskId);
  console.log('  âœ“ Market data fetched');

  // Stage 2: Zeckendorf Encoding (Ï†-based representation)
  console.log('Stage 2: Zeckendorf Encoding');
  const encodeTaskId = await swarm.submitTask({
    type: 'zeckendorf_encode',
    priority: TaskPriority.HIGH,
    payload: {
      numbers: marketData.data?.[0]?.data || [100, 150, 200],
      mode: 'phi_transform'
    },
    requiredCapabilities: ['zeckendorf_encoding']
  });

  const encoded = await swarm.getTaskResult(encodeTaskId);
  console.log('  âœ“ Zeckendorf encoding complete');

  // Stage 3: Nash Equilibrium Detection
  console.log('Stage 3: Nash Equilibrium Detection');
  const nashTaskId = await swarm.submitTask({
    type: 'nash_detection',
    priority: TaskPriority.URGENT,
    payload: {
      payoffMatrix: [
        [[3, 3], [0, 5]],
        [[5, 0], [1, 1]]
      ],
      playerCount: 2
    },
    requiredCapabilities: ['nash_equilibrium']
  });

  const equilibria = await swarm.getTaskResult(nashTaskId);
  console.log('  âœ“ Nash equilibria detected');

  // Stage 4: Knowledge Graph Update
  console.log('Stage 4: Knowledge Graph Update');
  const kgTaskId = await swarm.submitTask({
    type: 'knowledge_graph',
    priority: TaskPriority.NORMAL,
    payload: {
      feeds: ['https://finance.yahoo.com/rss']
    },
    requiredCapabilities: ['rss_ingestion']
  });

  const kgResult = await swarm.getTaskResult(kgTaskId);
  console.log('  âœ“ Knowledge graph updated');

  // Stage 5: Trading Strategy Execution
  console.log('Stage 5: Trading Strategy');
  const tradingTaskId = await swarm.submitTask({
    type: 'trading_strategy',
    priority: TaskPriority.CRITICAL,
    payload: {
      strategy: 'phi_momentum',
      market: marketData,
      encoded,
      equilibria
    },
    requiredCapabilities: ['strategy_execution']
  });

  const tradingSignal = await swarm.getTaskResult(tradingTaskId);
  console.log('  âœ“ Trading signal generated:', tradingSignal);

  // Stage 6: Consciousness Monitoring (Î¨)
  console.log('Stage 6: Consciousness Monitoring (Î¨)');
  const psiTaskId = await swarm.submitTask({
    type: 'consciousness_analysis',
    priority: TaskPriority.NORMAL,
    payload: {
      metrics: {
        coherence: 0.85,
        integration: 0.92,
        complexity: 0.78
      },
      threshold: 0.618 // Ï†-based threshold
    },
    requiredCapabilities: ['psi_monitoring']
  });

  const psiResult = await swarm.getTaskResult(psiTaskId);
  console.log(`  âœ“ Î¨ = ${psiResult.psi.toFixed(3)} ${psiResult.isEmergent ? 'ðŸ§  (EMERGENT)' : ''}`);

  // Final metrics
  const metrics = swarm.getPerformanceMetrics();
  console.log('\nðŸ“Š Pipeline Performance:');
  console.log(`   Total Tasks: ${metrics.totalTasks}`);
  console.log(`   Completed: ${metrics.completedTasks}`);
  console.log(`   Throughput: ${metrics.throughput.toFixed(2)} tasks/sec`);
  console.log(`   Avg Latency: ${metrics.avgLatency.toFixed(2)}ms`);
  console.log(`   Topology: ${metrics.topology}`);

  if (metrics.bottlenecks.length > 0) {
    console.log('\nâš ï¸  Detected Bottlenecks:');
    metrics.bottlenecks.forEach(bottleneck => {
      console.log(`   - [${bottleneck.severity.toUpperCase()}] ${bottleneck.description}`);
      console.log(`     â†’ ${bottleneck.recommendation}`);
    });
  }

  await swarm.stop();
}

/**
 * Demo 4: Single-Agent vs Swarm Performance Comparison
 */
async function demoPerformanceComparison() {
  console.log('\n\nðŸš€ Demo 4: Performance Comparison (Single-Agent vs Swarm)\n');

  const taskCount = 100;
  const taskPayload = {
    source: 'yahoo',
    symbols: ['SPY']
  };

  // Single-agent performance
  console.log('ðŸ“Š Single-Agent Performance...');
  const singleSwarm = createSwarm({
    topology: SwarmTopology.STAR,
    maxAgents: 1,
    minAgents: 1,
    scaling: { autoScale: false, scaleUpThreshold: 100, scaleDownThreshold: 0, cooldownPeriod: 0 }
  });

  await singleSwarm.start();
  await singleSwarm.spawnAgent(AgentType.DATA_INGESTION);

  const singleStartTime = Date.now();

  // Submit tasks sequentially
  for (let i = 0; i < taskCount; i++) {
    const taskId = await singleSwarm.submitTask({
      type: 'data_ingestion',
      priority: TaskPriority.NORMAL,
      payload: taskPayload
    });
    await singleSwarm.getTaskResult(taskId, 5000).catch(() => {});
  }

  const singleElapsed = Date.now() - singleStartTime;
  const singleMetrics = singleSwarm.getPerformanceMetrics();

  console.log(`   â±ï¸  Time: ${singleElapsed}ms`);
  console.log(`   ðŸ“ˆ Throughput: ${singleMetrics.throughput.toFixed(2)} tasks/sec`);
  console.log(`   âš¡ Avg Latency: ${singleMetrics.avgLatency.toFixed(2)}ms`);

  await singleSwarm.stop();

  // Swarm performance
  console.log('\nðŸ“Š Swarm Performance (10 agents)...');
  const multiSwarm = createSwarm({
    topology: SwarmTopology.MESH,
    maxAgents: 10,
    minAgents: 10,
    scaling: { autoScale: false, scaleUpThreshold: 100, scaleDownThreshold: 0, cooldownPeriod: 0 },
    scheduler: {
      enableWorkStealing: true,
      priorityLevels: 5,
      maxQueueSize: 1000,
      stealThreshold: 0.3
    }
  });

  await multiSwarm.start();

  // Spawn 10 agents
  await Promise.all(
    Array.from({ length: 10 }, () =>
      multiSwarm.spawnAgent(AgentType.DATA_INGESTION)
    )
  );

  const swarmStartTime = Date.now();

  // Submit all tasks in parallel
  const taskIds = await multiSwarm.submitBatch(
    Array.from({ length: taskCount }, () => ({
      type: 'data_ingestion',
      priority: TaskPriority.NORMAL,
      payload: taskPayload
    }))
  );

  await Promise.all(
    taskIds.map(id => multiSwarm.getTaskResult(id, 10000).catch(() => {}))
  );

  const swarmElapsed = Date.now() - swarmStartTime;
  const swarmMetrics = multiSwarm.getPerformanceMetrics();

  console.log(`   â±ï¸  Time: ${swarmElapsed}ms`);
  console.log(`   ðŸ“ˆ Throughput: ${swarmMetrics.throughput.toFixed(2)} tasks/sec`);
  console.log(`   âš¡ Avg Latency: ${swarmMetrics.avgLatency.toFixed(2)}ms`);
  console.log(`   ðŸ’¯ Utilization: ${(swarmMetrics.avgUtilization * 100).toFixed(1)}%`);

  await multiSwarm.stop();

  // Comparison
  const speedup = singleElapsed / swarmElapsed;
  const throughputImprovement = swarmMetrics.throughput / singleMetrics.throughput;
  const latencyImprovement = singleMetrics.avgLatency / swarmMetrics.avgLatency;

  console.log('\nðŸŽ¯ Performance Improvement:');
  console.log(`   âš¡ Speedup: ${speedup.toFixed(2)}x`);
  console.log(`   ðŸ“ˆ Throughput: ${throughputImprovement.toFixed(2)}x`);
  console.log(`   âš¡ Latency: ${latencyImprovement.toFixed(2)}x`);

  if (speedup >= 10) {
    console.log('   âœ… TARGET ACHIEVED: 10x throughput improvement!');
  } else {
    console.log(`   âš ï¸  Target: 10x (Current: ${speedup.toFixed(2)}x)`);
  }
}

/**
 * Demo 5: Auto-Scaling Demonstration
 */
async function demoAutoScaling() {
  console.log('\n\nðŸš€ Demo 5: Auto-Scaling Demonstration\n');

  const swarm = createSwarm({
    topology: SwarmTopology.ADAPTIVE,
    maxAgents: 30,
    minAgents: 4,
    agentdbConfig: {
      enableHNSW: true,
      quantization: 'uint8'
    },
    scaling: {
      autoScale: true,
      scaleUpThreshold: 70,
      scaleDownThreshold: 30,
      cooldownPeriod: 3000
    }
  });

  await swarm.start();

  // Start with minimal agents
  await Promise.all([
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.ENCODING),
    swarm.spawnAgent(AgentType.TRADING),
    swarm.spawnAgent(AgentType.CONSCIOUSNESS)
  ]);

  console.log('ðŸ“¦ Starting with 4 agents...\n');

  // Monitor scaling events
  swarm.on('agentSpawned', ({ agentId, type }) => {
    const state = swarm.getState();
    console.log(`   â†—ï¸  Scaled UP: ${type} (Total agents: ${state.activeAgents})`);
  });

  swarm.on('agentDespawned', ({ agentId }) => {
    const state = swarm.getState();
    console.log(`   â†˜ï¸  Scaled DOWN: ${agentId} (Total agents: ${state.activeAgents})`);
  });

  swarm.on('topologyUpdated', ({ topology }) => {
    console.log(`   ðŸ”„ Topology optimized: ${topology}`);
  });

  // Simulate increasing load
  console.log('ðŸ“ˆ Simulating increasing workload...');

  for (let wave = 1; wave <= 3; wave++) {
    console.log(`\nWave ${wave}: Submitting ${wave * 20} tasks`);

    const tasks = Array.from({ length: wave * 20 }, () => ({
      type: 'data_ingestion',
      priority: TaskPriority.NORMAL,
      payload: { source: 'yahoo', symbols: ['SPY'] }
    }));

    await swarm.submitBatch(tasks);
    await new Promise(resolve => setTimeout(resolve, 5000)); // Wait for auto-scaling

    const metrics = swarm.getPerformanceMetrics();
    console.log(`   Agents: ${metrics.activeAgents}, Utilization: ${(metrics.avgUtilization * 100).toFixed(1)}%`);
  }

  // Simulate decreasing load
  console.log('\nðŸ“‰ Simulating decreasing workload...');
  await new Promise(resolve => setTimeout(resolve, 10000)); // Wait for scale-down

  const finalMetrics = swarm.getPerformanceMetrics();
  console.log(`\nðŸ“Š Final State:`);
  console.log(`   Active Agents: ${finalMetrics.activeAgents}`);
  console.log(`   Utilization: ${(finalMetrics.avgUtilization * 100).toFixed(1)}%`);
  console.log(`   Topology: ${finalMetrics.topology}`);

  await swarm.stop();
}

/**
 * Demo 6: Bottleneck Detection
 */
async function demoBottleneckDetection() {
  console.log('\n\nðŸš€ Demo 6: Bottleneck Detection\n');

  const swarm = createSwarm({
    topology: SwarmTopology.HIERARCHICAL,
    maxAgents: 15
  });

  await swarm.start();

  // Create intentional bottleneck with imbalanced agents
  await Promise.all([
    swarm.spawnAgent(AgentType.DATA_INGESTION),
    swarm.spawnAgent(AgentType.ENCODING),
    swarm.spawnAgent(AgentType.ENCODING),
    swarm.spawnAgent(AgentType.ENCODING),
    swarm.spawnAgent(AgentType.NASH_DETECTION)
  ]);

  console.log('ðŸ“¦ Spawned agents with intentional imbalance\n');

  // Submit heavy encoding workload
  console.log('ðŸ“‹ Submitting encoding-heavy workload...');
  const tasks = Array.from({ length: 50 }, (_, i) => ({
    type: i % 5 === 0 ? 'data_ingestion' : 'zeckendorf_encode',
    priority: TaskPriority.NORMAL,
    payload: { numbers: [100, 200, 300] }
  }));

  await swarm.submitBatch(tasks);

  // Wait and check for bottlenecks
  await new Promise(resolve => setTimeout(resolve, 3000));

  const metrics = swarm.getPerformanceMetrics();

  console.log('\nðŸ“Š Performance Analysis:');
  console.log(`   Throughput: ${metrics.throughput.toFixed(2)} tasks/sec`);
  console.log(`   Avg Latency: ${metrics.avgLatency.toFixed(2)}ms`);

  if (metrics.bottlenecks.length > 0) {
    console.log('\nâš ï¸  Detected Bottlenecks:');
    metrics.bottlenecks.forEach((bottleneck, i) => {
      console.log(`\n   ${i + 1}. [${bottleneck.severity.toUpperCase()}] ${bottleneck.type}`);
      console.log(`      Description: ${bottleneck.description}`);
      console.log(`      Recommendation: ${bottleneck.recommendation}`);
      if (bottleneck.affectedAgents) {
        console.log(`      Affected: ${bottleneck.affectedAgents.join(', ')}`);
      }
    });
  } else {
    console.log('\nâœ… No bottlenecks detected');
  }

  await swarm.stop();
}

/**
 * Run all demos
 */
async function runAllDemos() {
  console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘     AgentDB Swarm Demonstration for AURELIA Ï†-Mechanics      â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

  try {
    await demoBasicSwarm();
    await demoParallelMarketData();
    await demoPhiMechanicsPipeline();
    await demoPerformanceComparison();
    await demoAutoScaling();
    await demoBottleneckDetection();

    console.log('\n\nâœ… All demos completed successfully!\n');

  } catch (error) {
    console.error('\nâŒ Demo error:', error);
    process.exit(1);
  }
}

/**
 * Main entry point
 */
if (require.main === module) {
  runAllDemos()
    .then(() => {
      console.log('ðŸŽ‰ AgentDB Swarm Demo Complete!');
      process.exit(0);
    })
    .catch(error => {
      console.error('Fatal error:', error);
      process.exit(1);
    });
}

// Export demos for selective running
export {
  demoBasicSwarm,
  demoParallelMarketData,
  demoPhiMechanicsPipeline,
  demoPerformanceComparison,
  demoAutoScaling,
  demoBottleneckDetection,
  runAllDemos
};
